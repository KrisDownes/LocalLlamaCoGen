{
    "name": "vscode-local-llm",
    "displayName": "Local LLM",
    "description": "VSCode extension for local LLM interaction",
    "version": "0.1.0",
    "engines": {
        "vscode": "^1.60.0"
    },
    "categories": [
        "Other"
    ],
    "activationEvents": [
        "onCommand:vscode-local-llm.invoke",
        "onCommand:vscode-local-llm.triggerCompletion",
        "onLanguage:typescript",
        "onLanguage:javascript",
        "onLanguage:python",
        "onLanguage:java",
        "onLanguage:cpp",
        "onLanguage:csharp"
    ],
    "main": "./out/extension.js",
    "contributes": {
        "commands": [
            {
                "command": "vscode-local-llm.invoke",
                "title": "Invoke Local LLM"
            },
            {
                "command": "vscode-local-llm.cancel",
                "title": "Cancel LLM Stream"
            },
            {
              "command": "vscode-local-llm.triggerCompletion",
              "title": "Trigger LLM Completion"
            },
            {
                "command": "vscode-local-llm.clearCache",
                "title": "Clear LLM Cache"
            },
            {
                "command": "vscode-local-llm.reloadModel",
                "title": "Reload LLM Model"
            }
        ],
        "keybindings": [
            {
                "command": "vscode-local-llm.invoke",
                "key": "ctrl+shift+l",
                "mac": "cmd+shift+l"
            },
            {
                "command": "vscode-local-llm.cancel",
                "key": "escape"
            },
            {
                "command": "vscode-local-llm.triggerCompletion",
                "key": "ctrl+space",
                "mac": "cmd+space",
                "when": "editorTextFocus"
            }
        ],
        "configuration": {
            "title": "localLLM",
            "properties": {
                "localLLM.modelPath": {
                    "type": "string",
                    "default": "",
                    "description": "Path to local Llama model"
                },
                "localLLM.apiUrl": {
                    "type": "string",
                    "default": "",
                    "description": "API URL for cloud LLM services"
                },
                "localLLM.apiKeyName": {
                    "type": "string",
                    "default": "",
                    "description": "Environment variable name for API key"
                },
                "localLLM.model": {
                    "type": "string",
                    "default": "",
                    "description": "Model identifier for cloud LLM services"
                },
                "localLLM.systemPrompt": {
                    "type": "string",
                    "default": "You are a Expert programming assistant and will generate the most professional and concise code. Think about your decisions and explore all possibilities but choose the most professional and concise.",
                    "description": "System prompt for the LLM"
                },
                "localLLM.replaceSelection": {
                    "type": "boolean",
                    "default": false,
                    "description": "Replace selected text with LLM output"
                },
                "localLLM.useLocalModel": {
                    "type": "boolean",
                    "default": true,
                    "description": "Use local model instead of cloud services"
                },
                "localLLM.maxTokens": {
                    "type": "number",
                    "default": 4096,
                    "description": "Maximum number of tokens to generate"
                },
                "localLLM.temperature": {
                    "type": "number",
                    "default": 0.7,
                    "minimum": 0,
                    "maximum": 2,
                    "description": "Temperature for text generation (higher = more creative)"
                },
                "localLLM.contextWindow": {
                    "type": "number",
                    "default": 5,
                    "description": "Number of preceding lines to include as context"
                },
                "localLLM.autoCompletion": {
                    "type": "boolean",
                    "default": true,
                    "description": "Enable automatic code completion suggestions"
                },
                "localLLM.completionDelay": {
                    "type": "number",
                    "default": 300,
                    "description": "Delay in milliseconds before triggering completion"
                }
            }
        }
    },
    "scripts": {
        "vscode:prepublish": "npm run compile",
        "compile": "tsc -p ./",
        "lint": "eslint src --ext ts",
        "watch": "tsc -watch -p ./",
        "clean": "rimraf out",
        "build": "npm run clean && npm run compile",
        "pretest": "npm run compile && npm run lint"
    },
    "devDependencies": {
        "@types/node": "^16.18.116",
        "@types/vscode": "^1.60.0",
        "@typescript-eslint/eslint-plugin": "^5.30.0",
        "@typescript-eslint/parser": "^5.30.0",
        "eslint": "^8.13.0",
        "rimraf": "^5.0.10",
        "typescript": "^4.9.5"
    }
}
